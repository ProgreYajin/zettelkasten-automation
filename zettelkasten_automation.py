import os
import json
import time
from dotenv import load_dotenv
load_dotenv()
from datetime import datetime
from typing import List, Dict, Optional
import requests
from notion_client import Client
import openai
from github import Github
import numpy as np

class ZettelkastenAutomation:
    """Zettelkastenãƒ¡ãƒ¢ã®è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    
    def __init__(self, notion_token: str, openai_api_key: str, github_token: str, 
                 database_id: str, repo_name: str, log_file: str = "processing_log.json"):
        """
        åˆæœŸåŒ–
        
        Args:
            notion_token: Notion APIãƒˆãƒ¼ã‚¯ãƒ³
            openai_api_key: OpenAI APIã‚­ãƒ¼
            github_token: GitHub Personal Access Token
            database_id: Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ID
            repo_name: GitHubãƒªãƒã‚¸ãƒˆãƒªå (ä¾‹: "username/repo")
            log_file: å‡¦ç†ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.notion = Client(auth=notion_token)
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        self.github = Github(github_token)
        self.database_id = database_id
        self.repo = self.github.get_repo(repo_name)
        
        # --- ä¿®æ­£ç®‡æ‰€ï¼šlogsãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹è¨­å®š ---
        log_dir = "logs"
        # logsãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆã™ã‚‹
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
            print(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {log_dir}")
            
        # ãƒ•ã‚©ãƒ«ãƒ€åã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çµåˆã™ã‚‹
        self.log_file = os.path.join(log_dir, log_file)
        # ---------------------------------------
        
        # å…¨ãƒšãƒ¼ã‚¸ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆé–¢é€£ãƒ¡ãƒ¢æ¤œç´¢ç”¨ï¼‰
        self.all_pages_cache = []
        
        # å‡¦ç†ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿
        self.processing_log = self._load_log()
        
    def _load_log(self) -> Dict:
        """å‡¦ç†ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {"processed_pages": {}}
    
    def _save_log(self):
        """å‡¦ç†ãƒ­ã‚°ã‚’ä¿å­˜"""
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.processing_log, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _is_already_processed(self, page_id: str, last_edited_time: str) -> bool:
        """ãƒšãƒ¼ã‚¸ãŒæ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯"""
        if page_id in self.processing_log["processed_pages"]:
            log_entry = self.processing_log["processed_pages"][page_id]
            # æœ€çµ‚ç·¨é›†æ™‚åˆ»ãŒå¤‰ã‚ã£ã¦ã„ãªã‘ã‚Œã°å‡¦ç†æ¸ˆã¿
            return log_entry.get("last_edited_time") == last_edited_time
        return False
    
    def _add_to_log(self, page_id: str, title: str, last_edited_time: str, status: str = "success"):
        """å‡¦ç†ãƒ­ã‚°ã«è¿½åŠ """
        self.processing_log["processed_pages"][page_id] = {
            "title": title,
            "processed_at": datetime.now().isoformat(),
            "last_edited_time": last_edited_time,
            "status": status
        }
        self._save_log()
    
    def get_unprocessed_pages(self) -> List[Dict]:
        """æœªå‡¦ç†ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        print("ğŸ“š Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœªå‡¦ç†ãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­...")
        pages = []
        has_more = True
        start_cursor = None
        
        while has_more:
            # StatusãŒã€Œæœªå‡¦ç†ã€ã¾ãŸã¯AIå‡¦ç†æ¸ˆã¿ãŒFalseã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
            response = self.notion.databases.query(
                database_id=self.database_id,
                start_cursor=start_cursor,
                filter={
                    "or": [
                        {
                            "property": "Status",
                            "select": {
                                "equals": "æœªå‡¦ç†"
                            }
                        },
                        {
                            "property": "AIå‡¦ç†æ¸ˆã¿",
                            "checkbox": {
                                "equals": False
                            }
                        }
                    ]
                }
            )
            pages.extend(response['results'])
            has_more = response['has_more']
            start_cursor = response.get('next_cursor')
            time.sleep(0.3)  # APIåˆ¶é™å¯¾ç­–
        
        # æœ€çµ‚ç·¨é›†æ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æœªå‡¦ç†ã®ã‚‚ã®ã ã‘ãƒ•ã‚£ãƒ«ã‚¿
        unprocessed = []
        for page in pages:
            last_edited = page['last_edited_time']
            if not self._is_already_processed(page['id'], last_edited):
                unprocessed.append(page)
        
        print(f"âœ… {len(unprocessed)}ãƒšãƒ¼ã‚¸ãŒæœªå‡¦ç†ã§ã™ï¼ˆå…¨{len(pages)}ãƒšãƒ¼ã‚¸ä¸­ï¼‰")
        return unprocessed
    
    def get_all_pages(self) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆé–¢é€£ãƒ¡ãƒ¢æ¤œç´¢ç”¨ï¼‰"""
        print("ğŸ“š å…¨ãƒšãƒ¼ã‚¸ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸­...")
        pages = []
        has_more = True
        start_cursor = None
        
        while has_more:
            response = self.notion.databases.query(
                database_id=self.database_id,
                start_cursor=start_cursor
            )
            pages.extend(response['results'])
            has_more = response['has_more']
            start_cursor = response.get('next_cursor')
            time.sleep(0.3)
            
        self.all_pages_cache = pages
        print(f"âœ… {len(pages)}ãƒšãƒ¼ã‚¸ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")
        return pages
    
    def get_page_content(self, page_id: str) -> str:
        """ãƒšãƒ¼ã‚¸ã®æœ¬æ–‡ã‚’å–å¾—"""
        blocks = self.notion.blocks.children.list(block_id=page_id)
        content = []
        
        for block in blocks['results']:
            block_type = block['type']
            if block_type == 'paragraph':
                text = self._extract_text(block['paragraph'])
                if text:
                    content.append(text)
            elif block_type in ['heading_1', 'heading_2', 'heading_3']:
                text = self._extract_text(block[block_type])
                if text:
                    content.append(f"\n## {text}\n")
            elif block_type == 'bulleted_list_item':
                text = self._extract_text(block['bulleted_list_item'])
                if text:
                    content.append(f"- {text}")
            elif block_type == 'numbered_list_item':
                text = self._extract_text(block['numbered_list_item'])
                if text:
                    content.append(f"1. {text}")
            elif block_type == 'to_do':
                text = self._extract_text(block['to_do'])
                checked = "âœ“" if block['to_do'].get('checked') else "â˜"
                if text:
                    content.append(f"{checked} {text}")
                    
        return '\n'.join(content)
    
    def _extract_text(self, block_content: Dict) -> str:
        """ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        if 'rich_text' not in block_content:
            return ''
        return ''.join([text['plain_text'] for text in block_content['rich_text']])
    
    def analyze_with_ai(self, content: str, existing_tags: List[str] = None) -> Dict:
        """AIã§ãƒ¡ãƒ¢ã‚’è§£æã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ã‚¿ã‚°ãƒ»è¦ç´„ã‚’ç”Ÿæˆ"""
        print("ğŸ¤– AIã§è§£æä¸­...")
        
        existing_tags_str = ', '.join(existing_tags) if existing_tags else 'ãªã—'
        
        prompt = f"""ä»¥ä¸‹ã®Zettelkastenãƒ¡ãƒ¢ã‚’è§£æã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¡ãƒ¢å†…å®¹ã€‘
{content[:3000]}  # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚

ã€æ—¢å­˜ã®ã‚¿ã‚°ã€‘
{existing_tags_str}

ä»¥ä¸‹ã®å½¢å¼ã§JSONã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
{{
  "title": "ã€Œã€œã€œã¯ã€‡ã€‡ã§ã‚ã‚‹ã€ã‚„ã€Œï½ãªã®ã¯ãªãœã‹ã€ã¨ã„ã£ãŸå½¢å¼ã®ç°¡æ½”ãªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3"],  // 3-5å€‹ã®ã‚¿ã‚°
  "summary": "100æ–‡å­—ç¨‹åº¦ã®è¦ç´„",
  "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3"]  // é–¢é€£ãƒ¡ãƒ¢æ¤œç´¢ç”¨ã®é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
}}

ã€ãƒ«ãƒ¼ãƒ«ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«ã¯å¿…ãšã€Œã€œã¯ã€‡ã€‡ã§ã‚ã‚‹ã€ã€Œã€œã«ã¤ã„ã¦ã€ã€Œã€œãªã®ã¯ãªãœã‹ã€ãªã©ã®å½¢å¼ã§ã€å†…å®¹ã®æœ¬è³ªã‚’è¡¨ç¾
- ã‚¿ã‚°ã¯æ—¢å­˜ã‚¿ã‚°ã‚‚è€ƒæ…®ã—ã¤ã¤ã€å†…å®¹ã«æœ€ã‚‚é©åˆ‡ãªã‚‚ã®ã‚’é¸æŠ
- keywordsã¯ã€ä»–ã®ãƒ¡ãƒ¢ã¨ãƒªãƒ³ã‚¯ã—ã‚„ã™ãã™ã‚‹ãŸã‚ã«ã€æ–‡ç« ã§ã¯ãªãå…·ä½“çš„ã§çŸ­ã„åè©ï¼ˆå›ºæœ‰åè©ã€æŠ€è¡“ç”¨èªã€æ¦‚å¿µï¼‰ã‚’5ã€œ8å€‹ç¨‹åº¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚å‡º"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯Zettelkastenæ–¹å¼ã®çŸ¥è­˜ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¡ãƒ¢ã®æœ¬è³ªã‚’æ‰ãˆã€é©åˆ‡ãªã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¿ã‚°ã‚’ä»˜ã‘ã‚‹ã“ã¨ãŒå¾—æ„ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            print(f"âœ… ã‚¿ã‚¤ãƒˆãƒ«: {result['title']}")
            print(f"âœ… ã‚¿ã‚°: {', '.join(result['tags'])}")
            print(f"âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(result.get('keywords', []))}")
            return result
            
        except Exception as e:
            print(f"âŒ AIè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "title": "ç„¡é¡Œã®ãƒ¡ãƒ¢",
                "tags": existing_tags or ["æœªåˆ†é¡"],
                "summary": content[:100],
                "keywords": []
            }
    
    def find_related_pages(self, keywords: List[str], current_page_id: str, 
                          top_k: int = 5) -> List[Dict]:
        """é–¢é€£ã™ã‚‹ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢"""
        print("ğŸ” é–¢é€£ãƒ¡ãƒ¢ã‚’æ¤œç´¢ä¸­...")
        
        if not keywords:
            return []
        
        related = []
        
        for page in self.all_pages_cache:
            if page['id'] == current_page_id:
                continue
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
            title = self._get_page_title(page)
            if not title or title == 'ç„¡é¡Œ':
                continue
            
            # ã‚¿ã‚°ã‚’å–å¾—
            page_tags = self._get_page_tags(page)
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—
            title_lower = title.lower()
            tags_lower = ' '.join(page_tags).lower()
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã§ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ
            title_matches = sum(1 for kw in keywords if kw.lower() in title_lower)
            
            # ã‚¿ã‚°ã§ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ
            tag_matches = sum(1 for kw in keywords if kw.lower() in tags_lower)
            
            # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒãƒƒãƒã‚’é‡è¦–ï¼‰
            score = title_matches * 2 + tag_matches
            
            if score > 0:
                related.append({
                    'id': page['id'],
                    'title': title,
                    'score': score
                })
        
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        related.sort(key=lambda x: x['score'], reverse=True)
        
        if related:
            print(f"âœ… {len(related[:top_k])}ä»¶ã®é–¢é€£ãƒ¡ãƒ¢ã‚’ç™ºè¦‹")
            for i, rp in enumerate(related[:top_k], 1):
                print(f"   {i}. {rp['title']} (ã‚¹ã‚³ã‚¢: {rp['score']})")
        else:
            print("â„¹ï¸  é–¢é€£ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        return related[:top_k]
    
    def _get_page_title(self, page: Dict) -> str:
        """ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
        try:
            title_property = page['properties'].get('Name') or page['properties'].get('title')
            if title_property and title_property['type'] == 'title':
                return ''.join([t['plain_text'] for t in title_property['title']])
        except:
            pass
        return ''
    
    def _get_page_tags(self, page: Dict) -> List[str]:
        """ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚°ã‚’å–å¾—"""
        try:
            tags_prop = page['properties'].get('Tags', {})
            if tags_prop.get('multi_select'):
                return [tag['name'] for tag in tags_prop['multi_select']]
        except:
            pass
        return []
    
    def update_notion_page(self, page_id: str, title: str, tags: List[str], 
                          related_pages: List[Dict]):
        """Notionãƒšãƒ¼ã‚¸ã‚’æ›´æ–°"""
        print("ğŸ“ Notionãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ä¸­...")
        
        try:
            # ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¿ã‚°ã€Statusã€AIå‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’æ›´æ–°
            properties = {
                'Name': {'title': [{'text': {'content': title}}]},
                'Tags': {'multi_select': [{'name': tag} for tag in tags]},
                'Status': {'select': {'name': 'å‡¦ç†æ¸ˆã¿'}},
                'AIå‡¦ç†æ¸ˆã¿': {'checkbox': True}
            }
            
            self.notion.pages.update(
                page_id=page_id,
                properties=properties
            )
            
            # é–¢é€£ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
            if related_pages:
                # æ—¢å­˜ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—
                existing_blocks = self.notion.blocks.children.list(block_id=page_id)
                
                # ã€Œé–¢é€£ãƒ¡ãƒ¢ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                has_related_section = False
                for block in existing_blocks['results']:
                    if block['type'] in ['heading_2', 'heading_3']:
                        text = self._extract_text(block[block['type']])
                        if 'é–¢é€£ãƒ¡ãƒ¢' in text:
                            has_related_section = True
                            break
                
                if not has_related_section:
                    children = [
                        {
                            'object': 'block',
                            'type': 'divider',
                            'divider': {}
                        },
                        {
                            'object': 'block',
                            'type': 'heading_2',
                            'heading_2': {
                                'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ”— é–¢é€£ãƒ¡ãƒ¢'}}]
                            }
                        }
                    ]
                    
                    for rp in related_pages:
                        children.append({
                            'object': 'block',
                            'type': 'paragraph',
                            'paragraph': {
                                'rich_text': [
                                    {'type': 'text', 'text': {'content': 'â†’ '}},
                                    {'type': 'mention', 'mention': {'type': 'page', 'page': {'id': rp['id']}}}
                                ]
                            }
                        })
                    
                    self.notion.blocks.children.append(block_id=page_id, children=children)
            
            print("âœ… Notionãƒšãƒ¼ã‚¸ã®æ›´æ–°å®Œäº†")
            
        except Exception as e:
            print(f"âŒ Notionæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def convert_to_markdown(self, page: Dict, content: str, tags: List[str], 
                           related_pages: List[Dict]) -> str:
        """Markdownå½¢å¼ã«å¤‰æ›ï¼ˆObsidianãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å¯¾å¿œç‰ˆï¼‰"""
        title = self._get_page_title(page)
        created_time = page['created_time'][:10]
        
        # --- ä¿®æ­£ç®‡æ‰€ï¼šã‚¿ã‚°ã®å‡¦ç† ---
        # 1. å„ã‚¿ã‚°ã‹ã‚‰ã€Œ#ã€ã‚’é™¤å»
        # 2. YAMLã®ãƒªã‚¹ãƒˆå½¢å¼ï¼ˆä¸€è¡Œãšã¤ï¼‰ã«ã™ã‚‹
        yaml_tags = ""
        if tags:
            yaml_tags = "\ntags:\n" + "\n".join([f"  - {tag.replace('#', '')}" for tag in tags])
        
        # YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¦ãƒ³ãƒˆã®çµ„ã¿ç«‹ã¦
        # titleã‚„dateã®å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ã‚‚ç¢ºå®Ÿã«ç¢ºä¿
        md = f"""---
title: {title}
date: {created_time}{yaml_tags}
---

# {title}

{content}
"""
        
        if related_pages:
            md += "\n---\n\n## ğŸ”— é–¢é€£ãƒ¡ãƒ¢\n\n"
            for rp in related_pages:
                md += f"- [[{rp['title']}]]\n"
        
        return md
    
    def save_to_github(self, filename: str, content: str, commit_message: str):
        """GitHubã«Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
        print(f"ğŸ“¤ GitHubã«ä¿å­˜ä¸­: {filename}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            try:
                file = self.repo.get_contents(filename)
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
                self.repo.update_file(
                    path=filename,
                    message=commit_message,
                    content=content,
                    sha=file.sha
                )
                print("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
            except:
                # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                self.repo.create_file(
                    path=filename,
                    message=commit_message,
                    content=content
                )
                print("âœ… æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
                
        except Exception as e:
            print(f"âŒ GitHubä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def process_page(self, page_id: str):
        """1ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†"""
        print(f"\n{'='*60}")
        print(f"å‡¦ç†é–‹å§‹: {page_id}")
        print('='*60)
        
        # ãƒšãƒ¼ã‚¸æƒ…å ±ã‚’å–å¾—
        page = self.notion.pages.retrieve(page_id=page_id)
        existing_title = self._get_page_title(page)
        last_edited_time = page['last_edited_time']
        
        # æœ¬æ–‡ã‚’å–å¾—
        content = self.get_page_content(page_id)
        if not content or len(content) < 20:
            print("â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: æœ¬æ–‡ãŒçŸ­ã™ãã¾ã™ï¼ˆ20æ–‡å­—æœªæº€ï¼‰")
            return
        
        # æ—¢å­˜ã®ã‚¿ã‚°ã‚’å–å¾—
        existing_tags = self._get_page_tags(page)
        
        # AIã§è§£æ
        analysis = self.analyze_with_ai(content, existing_tags)
        
        # é–¢é€£ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢
        related_pages = self.find_related_pages(
            analysis.get('keywords', []), 
            page_id
        )
        
        # Notionã‚’æ›´æ–°
        self.update_notion_page(
            page_id,
            analysis['title'],
            analysis['tags'],
            related_pages
        )
        
        # Markdownã«å¤‰æ›
        markdown = self.convert_to_markdown(
            page,
            content,
            analysis['tags'],
            related_pages
        )

        # --- ä¿®æ­£ç®‡æ‰€ï¼šä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€åã®å¤‰æ›´ ---
        target_dir = "zettelkasten-vault" # ãƒ•ã‚©ãƒ«ãƒ€åã‚’ã“ã“ã§æŒ‡å®š

        # GitHubã«ä¿å­˜
        safe_title = analysis['title'].replace('/', '-').replace('\\', '-')[:50]
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’å‰Šé™¤
        safe_title = ''.join(c for c in safe_title if c.isalnum() or c in (' ', '-', '_'))
        
        # ãƒ•ã‚©ãƒ«ãƒ€åã‚’ zettelkasten ã‹ã‚‰ zettelkasten-vault ã«å¤‰æ›´
        filename = f"{target_dir}/{page['created_time'][:10]}_{safe_title}.md"
        
        self.save_to_github(
            filename,
            markdown,
            f"âœ¨ Add: {analysis['title']}"
        )
        
        # ãƒ­ã‚°ã«è¨˜éŒ²
        self._add_to_log(page_id, analysis['title'], last_edited_time, "success")
        
        print(f"âœ… å‡¦ç†å®Œäº†: {analysis['title']}")
        time.sleep(1)  # APIåˆ¶é™å¯¾ç­–
    
    def run(self, limit: Optional[int] = None, force_reprocess: bool = False):
        """å…¨ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†
        
        Args:
            limit: å‡¦ç†ã™ã‚‹ãƒšãƒ¼ã‚¸æ•°ã®ä¸Šé™ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰
            force_reprocess: Trueã®å ´åˆã€å‡¦ç†æ¸ˆã¿ãƒšãƒ¼ã‚¸ã‚‚å†å‡¦ç†
        """
        print("\nğŸš€ Zettelkastenè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹\n")
        print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {self.log_file}\n")
        
        # å…¨ãƒšãƒ¼ã‚¸ã‚’å–å¾—ï¼ˆé–¢é€£ãƒ¡ãƒ¢æ¤œç´¢ç”¨ï¼‰
        self.get_all_pages()
        
        # æœªå‡¦ç†ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        if force_reprocess:
            print("âš ï¸  å¼·åˆ¶å†å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: å…¨ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†å¯¾è±¡ã¨ã—ã¾ã™")
            pages = self.all_pages_cache
        else:
            pages = self.get_unprocessed_pages()
        
        if not pages:
            print("âœ¨ å‡¦ç†å¯¾è±¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # å‡¦ç†å¯¾è±¡ã‚’åˆ¶é™
        if limit:
            pages = pages[:limit]
            print(f"â„¹ï¸  å‡¦ç†ã‚’{limit}ãƒšãƒ¼ã‚¸ã«åˆ¶é™ã—ã¾ã™")
        
        print(f"\nğŸ“Š å‡¦ç†å¯¾è±¡: {len(pages)}ãƒšãƒ¼ã‚¸\n")
        
        # å„ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†
        success_count = 0
        error_count = 0
        
        for i, page in enumerate(pages, 1):
            print(f"\né€²æ—: {i}/{len(pages)}")
            try:
                self.process_page(page['id'])
                success_count += 1
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                error_count += 1
                # ã‚¨ãƒ©ãƒ¼ã‚‚ãƒ­ã‚°ã«è¨˜éŒ²
                self._add_to_log(
                    page['id'], 
                    self._get_page_title(page) or "ã‚¿ã‚¤ãƒˆãƒ«å–å¾—å¤±æ•—",
                    page['last_edited_time'],
                    f"error: {str(e)}"
                )
                continue
        
        # å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼
        print("\n" + "="*60)
        print("ğŸ‰ å‡¦ç†å®Œäº†")
        print("="*60)
        print(f"âœ… æˆåŠŸ: {success_count}ãƒšãƒ¼ã‚¸")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_count}ãƒšãƒ¼ã‚¸")
        print(f"ğŸ“Š åˆè¨ˆ: {len(pages)}ãƒšãƒ¼ã‚¸")
        print("="*60)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
    NOTION_TOKEN = os.getenv('NOTION_TOKEN')
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
    DATABASE_ID = os.getenv('NOTION_DATABASE_ID')
    REPO_NAME = os.getenv('GITHUB_REPO')  # ä¾‹: "username/zettelkasten"
    
    if not all([NOTION_TOKEN, OPENAI_API_KEY, GITHUB_TOKEN, DATABASE_ID, REPO_NAME]):
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("\nå¿…è¦ãªç’°å¢ƒå¤‰æ•°:")
        print("  - NOTION_TOKEN")
        print("  - OPENAI_API_KEY")
        print("  - GITHUB_TOKEN")
        print("  - NOTION_DATABASE_ID")
        print("  - GITHUB_REPO")
        return
    
    # ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    system = ZettelkastenAutomation(
        notion_token=NOTION_TOKEN,
        openai_api_key=OPENAI_API_KEY,
        github_token=GITHUB_TOKEN,
        database_id=DATABASE_ID,
        repo_name=REPO_NAME,
        log_file="zettelkasten_processing_log.json"
    )
    
    # å®Ÿè¡Œ
    # åˆå›ãƒ†ã‚¹ãƒˆæ™‚ã¯limit=5ãªã©ã§åˆ¶é™æ¨å¥¨
    # force_reprocess=Trueã§å¼·åˆ¶å†å‡¦ç†
    system.run(limit=None, force_reprocess=False)


if __name__ == '__main__':
    main()